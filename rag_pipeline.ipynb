{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from sentence_transformers import SentenceTransformer\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-16T16:21:45.451344Z",
     "start_time": "2024-09-16T16:21:45.448107Z"
    }
   },
   "id": "61b772115f794890",
   "execution_count": 54
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "index_name = \"basic-200-index\"\n",
    "chunk_size = 100\n",
    "embedding_model = \"all-MiniLM-L6-v2\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-16T16:21:45.944798Z",
     "start_time": "2024-09-16T16:21:45.941730Z"
    }
   },
   "id": "8e8d6ba10518d3df",
   "execution_count": 55
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "data = \"only_english_data\"\n",
    "# Load API keys\n",
    "with open(\"pinecone_api_key.txt\") as f:\n",
    "    PINECONE_API_KEY = f.read().strip()\n",
    "\n",
    "# Load the models\n",
    "sentence_transformer_model = SentenceTransformer(embedding_model)\n",
    "dimension = sentence_transformer_model.get_sentence_embedding_dimension() \n",
    "\n",
    "# Initialize Pinecone\n",
    "pc = Pinecone(\n",
    "        api_key=PINECONE_API_KEY\n",
    "    )\n",
    "def create_index(pc, index_name, dimension):\n",
    "    existing_indexes = [index_info[\"name\"] for index_info in pc.list_indexes()]\n",
    "    if index_name not in existing_indexes:\n",
    "        pc.create_index(\n",
    "            name=index_name,\n",
    "            dimension=dimension,\n",
    "            metric='cosine',\n",
    "            spec=ServerlessSpec(\n",
    "                cloud=\"aws\",\n",
    "                region=\"us-east-1\"\n",
    "            ))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-16T16:21:47.966138Z",
     "start_time": "2024-09-16T16:21:47.572154Z"
    }
   },
   "id": "initial_id",
   "execution_count": 56
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "# Helper functions\n",
    "def load_data(directory: str):\n",
    "    \"\"\"Load all text files from a directory and its subdirectories.\"\"\"\n",
    "    documents = []\n",
    "    company_names = []\n",
    "    for foldername, _, filenames in os.walk(directory):\n",
    "        company_name = os.path.basename(foldername)\n",
    "        if company_name == 'only_english_data':\n",
    "            continue\n",
    "        for filename in filenames:\n",
    "            if filename.endswith(\".md\"):\n",
    "                filepath = os.path.join(foldername, filename)\n",
    "                with open(filepath, 'r', encoding='utf-8') as f:\n",
    "                    documents.append(f.read())\n",
    "                    company_names.append(company_name)  # Add company name for each document\n",
    "    return documents, company_names\n",
    "\n",
    "def chunk_data(documents: list, chunk_size: int, company_names: list):\n",
    "    \"\"\"Split documents into smaller chunks based on word count and prepend company names.\"\"\"\n",
    "    chunks = []\n",
    "    chunks_company = []\n",
    "    \n",
    "    for doc, company in zip(documents, company_names):\n",
    "        # Split the document into words\n",
    "        words = doc.split()\n",
    "        \n",
    "        # Create chunks based on word count\n",
    "        for i in range(0, len(words), chunk_size):\n",
    "            chunk = ' '.join(words[i:i + chunk_size])\n",
    "            chunks.append(chunk)\n",
    "            chunks_company.append(company)\n",
    "            \n",
    "    return chunks,chunks_company\n",
    "\n",
    "def embed_text(texts: list):\n",
    "    \"\"\"Embed texts using either Cohere or SentenceTransformer.\"\"\"\n",
    "    return sentence_transformer_model.encode(texts, convert_to_tensor=True).tolist()\n",
    "\n",
    "def upsert_index(index, embeddings, metadata, company_names, batch_size=100):\n",
    "    \"\"\"Insert embeddings into Pinecone in batches with metadata.\"\"\"\n",
    "    batch = []\n",
    "    \n",
    "    for idx, (emb, md, cn) in enumerate(zip(embeddings, metadata, company_names)):\n",
    "        vector = {\"id\": str(idx), \"values\": emb, \"metadata\": {\"text\": md, \"company_name\": cn}}\n",
    "        batch.append(vector)\n",
    "        \n",
    "        # When batch is full, upsert it\n",
    "        if len(batch) == batch_size:\n",
    "            index.upsert(vectors=batch)\n",
    "            batch = []  # Clear the batch\n",
    "\n",
    "    # Upsert any remaining vectors\n",
    "    if batch:\n",
    "        index.upsert(vectors=batch)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-16T16:22:31.938195Z",
     "start_time": "2024-09-16T16:22:31.928386Z"
    }
   },
   "id": "8c75e0f0c80c3119",
   "execution_count": 57
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load and Index Data\n",
    "documents, company_names = load_data(data)   \n",
    "chunks, company_names_chunks = chunk_data(documents, chunk_size, company_names)\n",
    "embeddings = embed_text(chunks)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-16T16:24:01.092869Z",
     "start_time": "2024-09-16T16:22:46.002756Z"
    }
   },
   "id": "3997f8dbda8a5bd6",
   "execution_count": 58
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "create_index(pc, index_name, dimension)\n",
    "index = pc.Index(index_name)\n",
    "upsert_index(index, embeddings, chunks, company_names_chunks)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-16T16:25:59.748091Z",
     "start_time": "2024-09-16T16:24:38.798414Z"
    }
   },
   "id": "f87929876fc166e8",
   "execution_count": 59
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "6546e9a0ce986780"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
