How we apply our content policies
=================================

UPDATED

SEP 3, 2024


------------------------

**What do we restrict?**

Our terms and policies define what is and isn't allowed on Facebook and Instagram. You can find further information on the restrictions we may impose on your use of Meta services in the [Facebook Terms of Service](https://www.facebook.com/legal/terms), [Instagram Terms of Use](https://help.instagram.com/581066165581870), [Facebook Community Standards](https://transparency.fb.com/policies/community-standards/?source=https%3A%2F%2Fwww.facebook.com%2Fcommunitystandards%2F), [Instagram Community Guidelines](https://help.instagram.com/477434105621119), [Advertising Standards](https://transparency.fb.com/policies/ad-standards/?source=https%3A%2F%2Fwww.facebook.com%2Fpolicies_center%2Fads), [Commerce Policies](https://www.facebook.com/policies_center/commerce), and some of our [other policies](https://transparency.fb.com/policies/other-policies).

If we determine content goes against our terms and policies, we take action on it. For example, we do not allow content that incites **violence or criminal behavior** (such as content promoting, supporting or praising dangerous organizations), compromises people’s **safety** (such as bullying and harassment, suicide and self-injury, and child or adult sexual exploitation), is **objectionable** (such as hate speech), is **inauthentic** (such as spam, misinformation or fake profiles) or that violates someone else’s **intellectual property**. More information on these policies is provided in the [Facebook Community Standards](https://transparency.fb.com/policies/community-standards/?source=https%3A%2F%2Fwww.facebook.com%2Fcommunitystandards%2F) and [Instagram Community Guidelines](https://help.instagram.com/477434105621119).

We may also impose restrictions in certain other circumstances. To learn more, see the following:

[Threat disruptions](https://transparency.fb.com/en-gb/metasecurity/threat-disruptions/)

[Security threats](https://transparency.fb.com/en-gb/metasecurity/security-threats)

[Intellectual property, Copyright](https://help.instagram.com/126382350847838?helpref=faq_content) and [Trademark](https://help.instagram.com/222826637847963?helpref=faq_content)

[Developer Policies](https://developers.facebook.com/devpolicy/)

[Facebook Content Monetisation Policies](https://www.facebook.com/business/help/1348682518563619?id=2520940424820218) and [Instagram Content Monetisation Policies](https://help.instagram.com/2635536099905516?fbclid=IwAR3Eu-uEzVvXiuA8yHEm_IWxaC3Ssn3NVV4-5LLJNG9yZUdDWzC6Le8IdIk)

[Facebook Partner Monetization Policies](https://www.facebook.com/business/help/169845596919485?id=2520940424820218) and [Instagram Partner Monetization Policies](https://help.instagram.com/512371932629820?fbclid=IwAR2b8W40Cg4D6N5usTpZNroTnexHLQx_kQEjLe1DgMHMJ6AqfzqScRSu8xU)

[Global restrictions](https://transparency.fb.com/data/content-restrictions/global/)

[Restrictions based on local law](https://transparency.fb.com/data/content-restrictions/content-violating-local-law/)

[Content Distribution Guidelines](https://transparency.fb.com/features/approach-to-ranking/types-of-content-we-demote/)

**How do we apply our policies?**

There are various procedures, measures and tools that we may use to moderate content on our services on the basis of our terms and policies.

We have content enforcement systems in place to take action when we determine something goes against our terms and policies. These form part of a three part approach – [remove](https://transparency.fb.com/enforcement/taking-action/taking-down-violating-content/), [reduce](https://transparency.fb.com/enforcement/taking-action/lowering-distribution-of-problematic-content/), [inform](https://transparency.fb.com/enforcement/taking-action/context-on-sensitive-misleading-content/):

* **Remove**: We remove content that goes against our policies as soon as we become aware of it.
    
* **Reduce**: Some problematic content can create a negative experience for people on Facebook and Instagram. We'll often reduce the distribution of this content, even when it doesn’t quite meet the standard for removal under our policies.
    
* **Inform**: When content is potentially sensitive or misleading, we sometimes add a warning or share additional information from independent fact-checkers.
    

To learn more about our enforcement policies, see [here](https://transparency.fb.com/enforcement/).

To implement this approach, Meta uses both technology and human review teams to [detect](https://transparency.fb.com/enforcement/detecting-violations/), [review](https://transparency.fb.com/enforcement/detecting-violations/) and [take action](https://transparency.fb.com/en-gb/enforcement/taking-action) on millions of pieces of content (which includes accounts) every day on Facebook and Instagram.

**_Technology_**

* Technology, including machine learning, is central to our content review process. Our technology proactively detects and removes the vast majority of violating content before anyone reports it. Our technology automates decisions for certain areas where content is highly likely to be violating and can take action on a new piece of content if it matches or comes very close to another piece of violating content. You can find more on [how our enforcement technology works here](https://transparency.fb.com/enforcement/detecting-violations/how-enforcement-technology-works).
    
* Technology also helps prioritise review. Whether content is reported by people or detected by Meta’s technology, automation helps us quickly route the content to human reviewers who have the right subject matter and language expertise. We then use technology to rank and prioritise content so our review teams can focus on the most important cases first. You can find more on [how technology helps prioritise review here](https://transparency.fb.com/enforcement/detecting-violations/technology-helps-prioritize-review).
    

**_Human Review Teams_**

* Our human review teams are located across the globe and review potential violations on Facebook and Instagram. They receive in-depth training and often specialise in certain policy areas and regions. When a piece of content requires further review, our technology sends it to a human review team to take a closer look and make the final decision. Our technology learns and improves from each decision. You can find more on [how review teams work here](https://transparency.fb.com/enforcement/detecting-violations/how-review-teams-work/).
    

**How do we assess reports of content violating local law?**

We also have specific procedures and processes in place to assess reports about content that may violate relevant local law.

When governments believe content on Facebook or Instagram goes against local law, they may report content for review. We may also receive court orders to restrict content or reports alleging content is unlawful in a particular country from non-government entities and members of the public.

We have a [robust process](https://transparency.fb.com/data/content-restrictions/content-violating-local-law/) for reviewing reports alleging that content on Facebook or Instagram go against local law.

* When we receive a report, we first review it against our policies, such as the Facebook Community Standards or Instagram Community Guidelines. If we determine that the content goes against our policies, we remove it. If content does not go against our policies, in line with our commitments as a member of the [Global Network Initiative](https://globalnetworkinitiative.org/) and our [Corporate Human Rights Policy](https://about.fb.com/wp-content/uploads/2021/03/Facebooks-Corporate-Human-Rights-Policy.pdf), we conduct a review to confirm whether the report is valid.
    
* In cases where we believe that reports are not legally valid, or are overly broad, or are inconsistent with international human rights standards, we may request clarification or take no action. Where a reporter frequently submits abusive reports that content goes against local law, we may suspend processing of such reports in line with our Misuse Policy [here](https://transparency.fb.com/enforcement/taking-action/misuse-policy).
    
* Where we act against content on the basis of local law rather than our policies such as the Facebook Community Standards or Instagram Community Guidelines, we generally restrict access to the content only in the jurisdiction where it is alleged to be unlawful and in most cases we do not impose any other penalties or feature restrictions. We also notify the affected user.
    
* When we act against Ads or Commerce content (such as Marketplace posts) on the basis of local law, we remove the content globally pursuant to our [Advertising Policies](https://www.facebook.com/policies/ads/) and [Commerce Policies](https://www.facebook.com/policies_center/commerce), respectively.
    
* When content violates intellectual property rights, we remove the content globally pursuant to our [Facebook Terms of Service](https://www.facebook.com/legal/terms) and [Instagram Terms of Use](https://help.instagram.com/581066165581870/).
    
* Where a user has frequently posted illegal content and we have repeatedly restricted access to their content on the basis of local law, we may impose suspensions per our Misuse Policy [here](https://transparency.fb.com/enforcement/taking-action/misuse-policy)
    
* If you disagree with a decision Meta has taken relating to content, you can find out about your options to request a review [here](https://transparency.fb.com/enforcement/taking-action/complaints-handling-process)